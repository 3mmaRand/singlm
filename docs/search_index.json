[
["index.html", "singlm: A simple introduction to GLM for analysing Poisson and Binomial responses in R Preface 0.1 Who is this book for? 0.2 Approach of this book 0.3 formatting options on the menu 0.4 Conventions used in the book 0.5 Overview of the chapter contents", " singlm: A simple introduction to GLM for analysing Poisson and Binomial responses in R Emma Rand 2020-07-28 Preface 0.1 Who is this book for? The aim of this book is to give people who have a little experience of doing data analysis in R a light introduction to Generalised Linear Models. It might be for you have done an introductory class in data analysis which covered classical univariate tests such as single linear regression, t-tests, one-way ANOVA and two-way ANOVA. It assumes you have some familiarity with R and RStudio and could import data, apply t.test() and aov() functions appropriately, interpret the results and create figures using ggplot(). It does not assume you are so fluent you could do these things with looking anything up, just that you would understand what you were doing and how to interpret the results. Secondary aim of this book is to introduce the terminology of statistical modelling to make your transition to more advanced texts easier. 0.2 Approach of this book One of the reasons functions such as t.test() and aov() are taught rather than lm() is because the output is usually easier for those new to data analysis to understand and interpret. However, the output of lm() is more typical of statistical modelling functions in general and this makes it difficult for people to take small steps forward in their the statistical repertoire. The approach taken in this book is to exploit preexisting knowledge of t-tests and ANOVA using t.test() and aov() to understand the output of lm(). This will allow us to more easily understand the output of glm() scope of the book, what isn’t covered Maths - intended to help you understand. ignore if it confuses you. 0.3 formatting options on the menu 0.4 Conventions used in the book With in the text Packages are indicated in bold code font like this: ggplot2 Functions are indicated in code font with brackets after their name like this: ggplot() The key point of a previous few paragraphs is in boxes like these Extra information and tips are in boxes like these objects in R are indicated in code font like this: mod stag we’ll be using tidyverse (Wickham et al. 2019) packages. we will use tidyverse throughout. Every chapter assumes it has been loaded. Other packages we will load explicitly. You can learn the tidyverse This book introduces the the Generalised Linear Model for two types of response: Binomially distributed: response variables are binary, that is, they can take one of only two values, such as “yes” or “no”, “alive” or “dead”, “present” or “absent” Poisson distributed: response variables that indicate the number of things and thus take discrete values from 0 up. In R, these are analysed with the glm() function. glm() can be used to perform tests using the Generalised Linear Model for response variables which are counts or binary. reporting and figures. it is not a ggplot tutorial. the code is given but not explained. to learn more go to : https://ggplot2.tidyverse.org/ 0.5 Overview of the chapter contents Chapter 1 A little revision of your introductory class. Chapter 2 In the first chapter we work through examples carried out in both lm() and their more more beginner friendly alternatives to gain a good understanding of the anatomy of lm() output. Chapter 3 … References "],
["revision-of-your-introductory-class.html", "Chapter 1 Revision of your Introductory class", " Chapter 1 Revision of your Introductory class In experimental design and execution we manipulate or choose one or more variables and record how changing their values effect another variable. The variables we manipulate or choose are called explanatory or predictor variables and the other is called the response. These are also known as independent and dependent variables respectively. Predictor, Explanatory, x and Independent: all terms used to describe the variables we choose. Predicted, Response, y and Dependent: all terms used to describe the variable we measure. When we plot data, the response variable goes on the y-axis and the explanatory variable goes on the x-axis If we have two explanatory variables we might indicate the different values of one of them with colour. In choosing between regression, t-tests, one-way ANOVA and two-way ANOVA we consider how many explanatory variables we have and whether they are continuous or categorical. If we have one explanatory variable and it is continuous, we can apply a regression; if it is a categorical variable with two groups (or levels) we have the choice of a t-test or a one way ANOVA but when there are more than two groups we use a one-way ANOVA. A two-way ANOVA is used when there are two categorical explanatory variables. These apparently different tests are, in fact, the same test. They have the same underlying mathematics and, or to put it another way, the follow the same model. That model is usually known as the General Linear Model. Running a test = building or fitting a model. tests of how well our data fit the model, tests for the model parameters against a null hypothesis In R t-tests and ANOVA, like regression, can be carried out with the lm() function. The output differs but the results themselves are identical. The model makes a prediction for the response variable for a given value of the explanatory variable. The difference between the predicted value and the observed value is the residual. lm() can be used to perform tests using the General Linear Model including t-tests, ANOVA and regression for response variables which are normally distributed. The General Linear Model requires that the response variable has residuals that follow the normal distribution with variance which is homogeneous for the values of the explanatory variables. This commonly occurs when the response variable has a normal distribution. The General_ised_ Linear Model* extends the General Linear Model by including response variables that do not follow the normal distribution. "],
["what-are-linear-models.html", "Chapter 2 What are linear models 2.1 What is a linear model?", " Chapter 2 What are linear models 2.1 What is a linear model? A linear model describes a continuous response variable as a function of one or more explanatory variables. When you have a single explanatory variable, that model is: \\[\\begin{equation} y_{i}=\\beta_{0}+\\beta_{1}X1_{i}+e_{i} \\tag{2.1} \\end{equation}\\] Where: The response variable is \\(y\\) and \\(X1\\) is the explanatory variable. \\(\\beta_{0}\\) and \\(\\beta_{1}\\) are the coefficients in the model. In a single linear regression, \\(\\beta_{0}\\) is often called the intercept and \\(\\beta_{1}\\) the slope. \\(i\\) is the index of the response so \\(y_{i}\\) is the \\(i\\)th response; if you had 20 pairs of \\(x\\)-\\(y\\) values, \\(i\\) would go from 1 to 20. \\(e_{i}\\) is the “error” also known as the residual. The equation means the response can be predicted from a given value of the explanatory variable, \\(\\beta_{0}\\) and \\(\\beta_{1}\\) and will take that value plus some random noise. When you build a linear model from your data the procedure estimates the model coefficients. See figure 2.1. This figure is referenced in later sections. the terms are replaced with their values for examples covered. Figure 2.1: A linear model annotated with the terms used in linear modelling. The measured response values are in pink, the predictions are in green, and the differences between these, known as the residuals, are in blue. The estimated model parameters, \\(\\beta_{0}\\) and \\(\\beta_{1}\\) are indicated. keypoint terminology build fit parameter, coefficient estimates If you have more than one explanatory variable this these are given as \\(X2\\), \\(X3\\) and so on up to the \\(p\\)th explanatory variable each with its own \\(\\beta\\) coefficient. The general form of the model is: \\[\\begin{equation} y_{i}=\\beta_{0}+\\beta_{1}X1_{i}+\\beta_{2}X2_{i}+...+\\beta_{p}XP_{i}+e_{i} \\tag{2.2} \\end{equation}\\] "],
["single-linear-regression.html", "Chapter 3 Single linear regression 3.1 Introduction to the example 3.2 Applying and interpreting lm() 3.3 Getting predictions from the model 3.4 Link to Chapter 2.1 3.5 Checking assumptions 3.6 Creating a figure 3.7 Reporting the results", " Chapter 3 Single linear regression 3.1 Introduction to the example This is a test you have probably carried out before. The concentration of juvenile hormone in stag beetles (Lucanus cervus) is known to influence mandible growth. Groups of stag beetles were injected with different concentrations of juvenile hormone (pg\\(\\mu\\)l-1) and their average mandible size (mm) determined. The data are in stag.txt. We will import the data with the read_table2() function from the readr package and plot it with ggplot() from the ggplot2 package. Both packages are part of the tidyverse. stag &lt;- read_table2(&quot;data-raw/stag.txt&quot;) Juvenile hormone is has been set by the experimenter and mandible size has decimal places and is something we would expect to be normally distributed. Visualising our data before any further analysis is usually sensible. In this case, it will help us determine if any relationship between the two variables is linear. ggplot(data = stag, aes(x = jh, y = mand)) + geom_point() The relationship between them looks roughly linear. So far, common sense suggests the assumptions of regression are met. 3.2 Applying and interpreting lm() The lm() function is used to build the regression model # build the statistical model mod &lt;- lm(data = stag, mand ~ jh) This can be read as: fit a linear of model of mandible size explained by juvenile growth hormone concentration. Printing mod to the console will reveal the estimated model parameters (coefficients) but little else: mod # # Call: # lm(formula = mand ~ jh, data = stag) # # Coefficients: # (Intercept) jh # 0.41934 0.00646 \\(\\beta_{0}\\) is labelled “(Intercept)” and \\(\\beta_{1}\\) is labelled “jh”. Thus the equation of the line is: \\(mand\\) = 0.419 + 0.006\\(jh\\) More information including statistical tests of the model and its parameters is obtained by using summary() # examine it summary(mod) # # Call: # lm(formula = mand ~ jh, data = stag) # # Residuals: # Min 1Q Median 3Q Max # -0.3860 -0.2028 -0.0975 0.1503 0.6069 # # Coefficients: # Estimate Std. Error t value Pr(&gt;|t|) # (Intercept) 0.41934 0.13943 3.01 0.0094 ** # jh 0.00646 0.00158 4.08 0.0011 ** # --- # Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # # Residual standard error: 0.292 on 14 degrees of freedom # Multiple R-squared: 0.543, Adjusted R-squared: 0.51 # F-statistic: 16.6 on 1 and 14 DF, p-value: 0.00113 The “Coefficients:” table gives the estimated \\(\\beta_{0}\\) and \\(\\beta_{1}\\) again, this time with their standard errors and tests of whether the estimates differ from zero. The estimated value for the intercept is 0.419 \\(\\pm\\) 0.139 and this differs significantly from zero (\\(p\\) = 0.009). The estimated value for the slope, 0.006 \\(\\pm\\) 0.002, also differs significantly from zero (\\(p\\) = 0.001). The three lines at the bottom of the output gives information about the fit of the model to the data. The “Multiple R-squared” gives the proportion of the variance in the response which is explained by the model. In our case, 0.543 of the variance in mandible length is explained by the model and this is a significant proportion of that variance (\\(p\\) = 0.001). For a single linear regression, the p-value for the model and the p-value for the slope are the same. This is also true for linear models in the form of a two-sample t-test but not the case for other linear models. 3.3 Getting predictions from the model The predict() returns the predicted values of the response. To add a column of predicted values to the dataframe: stag$pred &lt;- predict(mod) This requires creating a data frame of the x values from which you want to predict predictions &lt;- data.frame(jh = seq(0, 150, 5)) Note that the name and type of value of explanatory variable must be the same as it is in the model predictions$pred &lt;- predict(mod, newdata = predictions) 3.4 Link to Chapter 2.1 Replacing the terms shown in Figure 2.1 with the values in this example gives us 3.1. Figure 3.1: The annotated model with the values from the stag beetle example. The measured response values are in pink, the predictions are in green, and the residuals, are in blue. One example of a measured value, a predicted value and the residual is shown for a Juvenile hormone of 130 pg\\(\\mu\\)l-1. The estimated model parameters, \\(\\beta_{0}\\) and \\(\\beta_{1}\\) are indicated. Compare to Figure 2.1. 3.5 Checking assumptions plot(mod, which = 2) plot(mod, which = 1) shapiro.test(mod$res) # # Shapiro-Wilk normality test # # data: mod$res # W = 0.9, p-value = 0.4 3.6 Creating a figure ggplot(data = stag, aes(x = jh, y = mand)) + geom_point() + scale_x_continuous(expand = c(0.01, 0), limits = c(0, 160), name = expression(paste(&quot;Juvenile hormone (pg&quot;, mu, l^-1, &quot;)&quot;))) + scale_y_continuous(expand = c(0, 0), limits = c(0, 2), name = &quot;Mandible length (mm)&quot;) + geom_smooth(method = lm, se = FALSE, colour = &quot;black&quot;) + theme_classic() 3.7 Reporting the results There was a significant positive relationship between the concentration of Juvenile hormone and mandible length (\\(\\beta_{1}\\pm s.e.\\): 0.006 \\(\\pm\\) 0.002; \\(p\\) = 0.001). See figure 3.2. Figure 3.2: Relationship between the concentration of Juvenile hormone and mandible length. "],
["t-tests-revisit.html", "Chapter 4 t-tests revisited 4.1 Introduction to the example 4.2 t.test() output reminder 4.3 Applying and interpreting lm() 4.4 Getting predictions from the model 4.5 Link to Chapter 2.1 4.6 Checking assumptions 4.7 Creating a figure 4.8 Reporting the results", " Chapter 4 t-tests revisited 4.1 Introduction to the example Some plant biotechnologists developed a genetically modified line of Cannabis sativa to increase its omega 3 fatty acids content. They grew 50 wild type and fifty modified plants to maturity, collect the seeds and measure the amount of omega 3 fatty acids. The data are in csativa.txt. They used a two-sample t-test to compare the mean omega 3 content in the two plant types. We again use the read_table2() function to import the data and visualise it with ggplot() csativa &lt;- read_table2(&quot;data-raw/csativa.txt&quot;) # create a rough plot of the data ggplot(data = csativa, aes(x = plant, y = omega)) + geom_violin() The modified plant have a lower mean omega 3 content than the wildtype plants. The modification appears not to be successful. Statistical comparison of the two means can be done with either the t.test() or lm() functions; these are exactly equivalent but present the results differently. We will use our understanding of applying and interpreting t.test() to develop our understanding of lm() output 4.2 t.test() output reminder t.test(data = csativa, omega ~ plant, var.equal = TRUE) # # Two Sample t-test # # data: omega by plant # t = -5, df = 98, p-value = 2e-06 # alternative hypothesis: true difference in means is not equal to 0 # 95 percent confidence interval: # -9.69 -4.21 # sample estimates: # mean in group modif mean in group wild # 49.5 56.4 The two groups means are give in the section labelled “sample estimates” and the test of whether they differ significantly is given in the forth line (beginning “t = …”). We conclude the mean omega 3 content of the modified plants (49.465 units) is significantly lower than that of the wildtype plants (\\(t\\) = 5.029, \\(d.f.\\) = 98, \\(p\\) &lt; 0.001). The confidence interval is on the difference between the two means. The sign on the \\(t\\) value and the order in which the sample estimates are given is determined by R’s alphabetical ordering of the groups. As “modif” comes before “wildtype” in the alphabet, “modif” is the first group and the test is the modified plant mean minus the wildtype mean. This has no impact on our conclusions and had the wildtype plants been labelled “control” the output would be: Two Sample t-test data: omega by plant t = 5.0289, df = 98, p-value = 2.231e-06 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: 4.205372 9.687828 sample estimates: mean in group control mean in group modif 56.4118 49.4652 4.3 Applying and interpreting lm() The lm() function is used as follows: # build a model with `lm()` mod &lt;- lm(omega ~ plant, data = csativa) This can be read as: fit a linear of model of omega content explained by plant type. Printing mod to the console gives us these estimated model parameters (coefficients): mod # # Call: # lm(formula = omega ~ plant, data = csativa) # # Coefficients: # (Intercept) plantwild # 49.47 6.95 order of the groups as it was with t.test() this is standard in r plantwild variablelevel summary(mod) # # Call: # lm(formula = omega ~ plant, data = csativa) # # Residuals: # Min 1Q Median 3Q Max # -15.872 -3.703 -0.964 4.460 16.918 # # Coefficients: # Estimate Std. Error t value Pr(&gt;|t|) # (Intercept) 49.465 0.977 50.64 &lt; 2e-16 *** # plantwild 6.947 1.381 5.03 2.2e-06 *** # --- # Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # # Residual standard error: 6.91 on 98 degrees of freedom # Multiple R-squared: 0.205, Adjusted R-squared: 0.197 # F-statistic: 25.3 on 1 and 98 DF, p-value: 2.23e-06 4.4 Getting predictions from the model predictions &lt;- data.frame(plant = c(&quot;modif&quot;, &quot;wild&quot;)) predictions$pred &lt;- predict(mod, newdata = predictions) 4.5 Link to Chapter 2.1 Replacing the terms shown in Figure 2.1 with the values in this example gives us 4.1. Figure 4.1: The annotated model with the values from the Omega 3 content of Cannabis sativa example. The measured response values are in pink, the predictions are in green, and the residuals, are in blue. One example of a measured value, a predicted value and the residual is shown for a wildtype individual. The estimated model parameters, \\(\\beta_{0}\\) and \\(\\beta_{1}\\) are indicated. Compare to Figure 2.1. 4.6 Checking assumptions plot(mod, which = 2) plot(mod, which = 1) shapiro.test(mod$res) # # Shapiro-Wilk normality test # # data: mod$res # W = 1, p-value = 0.5 4.7 Creating a figure csativa_summary &lt;- csativa %&gt;% group_by(plant) %&gt;% summarise(mean = mean(omega), std = sd(omega), n = length(omega), se = std/sqrt(n)) #summarise the data ggplot() + geom_jitter(data = csativa, aes(x = plant, y = omega), width = 0.25, colour = &quot;grey&quot;) + geom_errorbar(data = csativa_summary, aes(x = plant, ymin = mean, ymax = mean), width = .3) + geom_errorbar(data = csativa_summary, aes(x = plant, ymin = mean - se, ymax = mean + se), width = .5) + geom_segment(aes(x = 1, y = 75, xend = 2, yend = 75), size = 1) + geom_segment(aes(x = 1, y = 75, xend = 1, yend = 73), size = 1) + geom_segment(aes(x = 2, y = 75, xend = 2, yend = 73), size = 1) + annotate(&quot;text&quot;, x = 1.5, y = 77, label = &quot;***&quot;, size = 6) + scale_x_discrete(labels = c(&quot;Modified&quot;, &quot;Wild Type&quot;), name = &quot;Plant type&quot;) + scale_y_continuous(name = &quot;Amount of Omega 3 (units)&quot;, expand = c(0, 0), limits = c(0, 90)) + theme_classic() 4.8 Reporting the results res &lt;- summary(mod) tval &lt;- res$coefficients[&quot;plantwild&quot;, &quot;t value&quot;] df &lt;- res$df[2] if (res$coefficients[&quot;plantwild&quot;, &quot;Pr(&gt;|t|)&quot;] &lt; 0.001) { b1p = &quot;&lt; 0.001&quot; } if (res$coefficients[&quot;plantwild&quot;, &quot;Pr(&gt;|t|)&quot;] &gt; 0.001) { b1p = paste(&quot;=&quot;, round(res$coefficients[&quot;plantwild&quot;, &quot;Pr(&gt;|t|)&quot;], 3)) } The genetic modification was unsuccessful with wild type plants (\\(\\bar{x} \\pm s.e.\\): 56.412 \\(\\pm\\) 1.11 units) have significantly higher omega 3 than modified plants(49.465 \\(\\pm\\) 0.823 units) (\\(t\\) = 5.029; \\(d.f.\\) = 98; \\(p\\) &lt; 0.001). See figure 4.2. Figure 4.2: Relationship between the concentration of Juvenile hormone and mandible length. "],
["one-way-anova-revisit.html", "Chapter 5 One-way ANOVA revisited 5.1 Introduction to the example 5.2 aov() output reminder 5.3 Post-hoc testing for aov() 5.4 Applying and interpreting lm() 5.5 Getting predictions from the model 5.6 Link to Chapter 2.1 5.7 Checking assumptions 5.8 Post-hoc testing for lm() 5.9 Creating a figure 5.10 Reporting the results", " Chapter 5 One-way ANOVA revisited 5.1 Introduction to the example The myoglobin concentration of skeletal muscle of three species of seal in grams per kilogram of muscle was determined and the data are given in seal.txt. We want to know if there is a difference in myoglobin concentration between species. Each row represents an individual seal. Figure 5.1 Figure 5.1: Baby Weddell Seals are very cute. By Photo © Samuel Blanc, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=3877642 seal &lt;- read_delim(&quot;data-raw/seal.txt&quot;, delim = &quot; &quot;) seal$species &lt;- factor(seal$species) make a factor because we will later use an r function that demands that # create a rough plot of the data ggplot(data = seal, aes(x = species, y = myoglobin)) + geom_violin() seal_summary &lt;- seal %&gt;% group_by(species) %&gt;% summarise(mean = mean(myoglobin), std = sd(myoglobin), n = length(myoglobin), se = std/sqrt(n)) species mean std n se Bladdernose Seal 42.3 8.02 30 1.46 Harbour Seal 49.0 8.25 30 1.51 Weddell Seal 44.7 7.85 30 1.43 5.2 aov() output reminder mod &lt;- aov(data = seal, myoglobin ~ species) summary(mod) # Df Sum Sq Mean Sq F value Pr(&gt;F) # species 2 692 346 5.35 0.0064 ** # Residuals 87 5627 65 # --- # Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 There was a significant difference in myoglobin concentration between Seal species (ANOVA: \\(F\\) = 5.352; \\(d.f.\\) = 2, 87; \\(p\\) = 0.006). We need a post-hoc test to discover which comparisons are significant. 5.3 Post-hoc testing for aov() TukeyHSD(mod) # Tukey multiple comparisons of means # 95% family-wise confidence level # # Fit: aov(formula = myoglobin ~ species, data = seal) # # $species # diff lwr upr p adj # Harbour Seal-Bladdernose Seal 6.69 1.74 11.646 0.005 # Weddell Seal-Bladdernose Seal 2.34 -2.61 7.296 0.499 # Weddell Seal-Harbour Seal -4.35 -9.30 0.602 0.097 Post-hoc testing revealed the difference to be between the Harbour Seal with the highest myoglobin concentrations (\\(\\bar{x} \\pm s.e.\\): 49.01 \\(\\pm\\) 1.507) ) and the Bladdernose Seal with the lowest (\\(\\bar{x} \\pm s.e.\\): 42.316 \\(\\pm\\) 1.464). 5.4 Applying and interpreting lm() mod &lt;- lm(data = seal, myoglobin ~ species) mod # # Call: # lm(formula = myoglobin ~ species, data = seal) # # Coefficients: # (Intercept) speciesHarbour Seal speciesWeddell Seal # 42.32 6.69 2.34 The mean of Bladdernose Seals is (42.32). It is the intercept (\\(\\beta_{0}\\)) because “Bladdernose Seal” comes before “Harbour Seal” and “Weddell Seal” in the alphabet. The value labelled “speciesHarbour Seal” is the difference between the intercept and the Harbour Seal mean. It indicates that you have to add 6.69 to 42.32 to get the Harbour Seal mean The value labelled “speciesWedell Seal” is also relative to the intercept. The value of 2.34 must be added to 42.32 to get the Weddell Seal mean. 5.5 Getting predictions from the model predictions &lt;- data.frame(species = seal_summary$species) predictions$pred &lt;- predict(mod, newdata = predictions) 5.6 Link to Chapter 2.1 Replacing the terms shown in Figure 2.1 with the values in this example gives us 5.2. Figure 5.2: The annotated model with the values from the myoglobin content of seal muscle example. The measured response values are in pink, the predictions are in green, and the residuals, are in blue. One example of a measured value, a predicted value and the residual is shown for a Harbour Seal individual. The estimated model parameters, \\(\\beta_{0}\\) and \\(\\beta_{1}\\) are indicated. Compare to Figure 2.1. 5.7 Checking assumptions plot(mod, which = 2) plot(mod, which = 1) shapiro.test(mod$res) # # Shapiro-Wilk normality test # # data: mod$res # W = 1, p-value = 0.4 5.8 Post-hoc testing for lm() library(multcomp) generic example. define linfct, mcp multiple comparion procedures mod_mc &lt;- glht(mod, linfct = mcp(species = &quot;Tukey&quot;)) summary(mod_mc) # # Simultaneous Tests for General Linear Hypotheses # # Multiple Comparisons of Means: Tukey Contrasts # # # Fit: lm(formula = myoglobin ~ species, data = seal) # # Linear Hypotheses: # Estimate Std. Error t value Pr(&gt;|t|) # Harbour Seal - Bladdernose Seal == 0 6.69 2.08 3.22 0.005 ** # Weddell Seal - Bladdernose Seal == 0 2.34 2.08 1.13 0.499 # Weddell Seal - Harbour Seal == 0 -4.35 2.08 -2.09 0.097 . # --- # Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # (Adjusted p values reported -- single-step method) 5.9 Creating a figure #summarise the data ggplot() + geom_jitter(data = seal, aes(x = species, y = myoglobin), width = 0.25, colour = &quot;grey&quot;) + geom_errorbar(data = seal_summary, aes(x = species, ymin = mean, ymax = mean), width = .3) + geom_errorbar(data = seal_summary, aes(x = species, ymin = mean - se, ymax = mean + se), width = .5) + geom_segment(aes(x = 1, y = 71, xend = 3, yend = 71), size = 1) + geom_segment(aes(x = 1, y = 71, xend = 1, yend = 69), size = 1) + geom_segment(aes(x = 3, y = 71, xend = 3, yend = 69), size = 1) + annotate(&quot;text&quot;, x = 2, y = 73, label = &quot;**&quot;, size = 6) + scale_x_discrete(name = &quot;Species&quot;) + scale_y_continuous(name = expression(&quot;Myoglobin concentration g &quot;*Kg^{-1}), expand = c(0, 0), limits = c(0, 75)) + theme_classic() 5.10 Reporting the results # res &lt;- summary(mod) # tval &lt;- res$coefficients[&quot;specieswild&quot;, &quot;t value&quot;] # df &lt;- res$df[2] There is a significant difference in myoglobin concentration between Seal species (ANOVA: \\(F\\) = 5.352; \\(d.f.\\) = 2, 87; \\(p\\) = 0.006). Post-hoc testing revealed that difference to be between the Harbour Seal with the highest myoglobin concentrations (\\(\\bar{x} \\pm s.e.\\): 49.01 \\(\\pm\\) 1.507) ) and the Bladdernose Seal with the lowest (\\(\\bar{x} \\pm s.e.\\): 42.316 \\(\\pm\\) 1.464). See figure 5.3. Figure 5.3: Muscle myoglobin content of three seal species. "],
["two-way-anova-revisit.html", "Chapter 6 Two-way ANOVA revisited 6.1 Introduction to the example 6.2 aov() output reminder 6.3 Post-hoc testing for aov 6.4 Applying and interpreting lm() 6.5 Getting predictions from the model 6.6 Link to Chapter 2.1 6.7 Checking assumptions 6.8 Post-hoc testing for lm() 6.9 Creating a figure 6.10 Reporting the results", " Chapter 6 Two-way ANOVA revisited 6.1 Introduction to the example A group of amateur conchologists have collected live specimens of two species of rough periwinkle (intertidal, gastropod molluscs) from sites in northern England in the Spring (1) and Summer (2). Among other variables, they take a measure of the gut parasite load. Number of parasites is related to the number of parasites seen on a slide of gut contents and larger numbers indicate a higher parasite load. The data are in S periwinkle.txt. periwinkle &lt;- read_delim(&quot;data-raw/periwinkle.txt&quot;, delim = &quot;\\t &quot;) periwinkle$species &lt;- factor(periwinkle$species) periwinkle$season &lt;- factor(periwinkle$season) Do a quick plot of the data. We have two explanatory variables: one can be mapped to the x-axis and the is mapped to a different aesthetic. We have used fill. ggplot(data = periwinkle, aes(x = season, y = para, fill = species)) + geom_violin() peri_summary &lt;- periwinkle %&gt;% group_by(season, species) %&gt;% summarise(mean = mean(para), sd = sd(para), n = length(para), se = sd / sqrt(n)) season species mean sd n se Spring Littorina nigrolineata 63.8 11.92 25 2.38 Spring Littorina saxatilis 56.5 8.88 25 1.78 Summer Littorina nigrolineata 69.4 11.44 25 2.29 Summer Littorina saxatilis 72.9 11.24 25 2.25 6.2 aov() output reminder mod &lt;- aov(data = periwinkle, para ~ season * species) summary(mod) # Df Sum Sq Mean Sq F value Pr(&gt;F) # season 1 3058 3058 25.58 2e-06 *** # species 1 90 90 0.75 0.387 # season:species 1 724 724 6.05 0.016 * # Residuals 96 11477 120 # --- # Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 res &lt;- summary(mod)[[1]] df_seas &lt;- res$Df[1] df_sp &lt;- res$Df[2] df_seasxsp &lt;- res$Df[3] df_err &lt;- res$Df[4] fval_seas &lt;- res$`F value`[1] fval_sp &lt;- res$`F value`[2] fval_seasxsp &lt;- res$`F value`[3] if (res$`Pr(&gt;F)`[1] &lt; 0.001) { pval_seas = &quot;&lt; 0.001&quot; } if (res$`Pr(&gt;F)`[1] &gt; 0.001) { pval_seas = paste(&quot;=&quot;, round(res$`Pr(&gt;F)`[1], 3)) } if (res$`Pr(&gt;F)`[2] &lt; 0.001) { pval_sp = &quot;&lt; 0.001&quot; } if (res$`Pr(&gt;F)`[2] &gt; 0.001) { pval_sp = paste(&quot;=&quot;, round(res$`Pr(&gt;F)`[2], 3)) } if (res$`Pr(&gt;F)`[3] &lt; 0.001) { pval_seasxsp = &quot;&lt; 0.001&quot; } if (res$`Pr(&gt;F)`[3] &gt; 0.001) { pval_seasxsp = paste(&quot;=&quot;, round(res$`Pr(&gt;F)`[3], 3)) } There was a significantly greater number of parasites in the Summer than the Spring (ANOVA: \\(F\\) = 25.58; \\(d.f.\\) = 1, 96; \\(p\\) &lt; 0.001). There was no difference between the species when averaged across the season but there was significant interaction (ANOVA: \\(F\\) = 6.053; \\(d.f.\\) = 1, 96; \\(p\\) = 0.016) between season and species with higher numbers infecting L.nigrolineata in the Spring whilst L.saxatilis was more heavily parasitized in the Summer. We need a post-hoc test to discover which comparisons are significant. 6.3 Post-hoc testing for aov TukeyHSD(mod) # Tukey multiple comparisons of means # 95% family-wise confidence level # # Fit: aov(formula = para ~ season * species, data = periwinkle) # # $season # diff lwr upr p adj # Summer-Spring 11.1 6.72 15.4 0 # # $species # diff lwr upr p adj # Littorina saxatilis-Littorina nigrolineata -1.9 -6.24 2.44 0.387 # # $`season:species` # diff lwr # Summer:Littorina nigrolineata-Spring:Littorina nigrolineata 5.68 -2.41 # Spring:Littorina saxatilis-Spring:Littorina nigrolineata -7.28 -15.37 # Summer:Littorina saxatilis-Spring:Littorina nigrolineata 9.16 1.07 # Spring:Littorina saxatilis-Summer:Littorina nigrolineata -12.96 -21.05 # Summer:Littorina saxatilis-Summer:Littorina nigrolineata 3.48 -4.61 # Summer:Littorina saxatilis-Spring:Littorina saxatilis 16.44 8.35 # upr p adj # Summer:Littorina nigrolineata-Spring:Littorina nigrolineata 13.766 0.263 # Spring:Littorina saxatilis-Spring:Littorina nigrolineata 0.806 0.093 # Summer:Littorina saxatilis-Spring:Littorina nigrolineata 17.246 0.020 # Spring:Littorina saxatilis-Summer:Littorina nigrolineata -4.874 0.000 # Summer:Littorina saxatilis-Summer:Littorina nigrolineata 11.566 0.675 # Summer:Littorina saxatilis-Spring:Littorina saxatilis 24.526 0.000 Note that the output is wrapped because the names associated with each comparison, for example “Summer:Littorina nigrolineata-Spring:Littorina nigrolineata”, are quite long. L.saxatilis has fewer parasites in the spring than L.nigrolineata (\\(p\\) = 0.02) but this rises significantly in Summer (\\(p\\) &lt; 0.001) while that of L.nigrolineata does not. 6.4 Applying and interpreting lm() mod &lt;- lm(data = periwinkle, para ~ season * species) mod # # Call: # lm(formula = para ~ season * species, data = periwinkle) # # Coefficients: # (Intercept) # 63.76 # seasonSummer # 5.68 # speciesLittorina saxatilis # -7.28 # seasonSummer:speciesLittorina saxatilis # 10.76 The mean of L.nigrolineata in the Spring is (63.76). It is the intercept (\\(\\beta_{0}\\)) because “Littorina nigrolineata” comes before “Littorina saxatilis” and “Spring” comes before “Summer” in the alphabet. The value labelled “seasonSummer” is the difference between the intercept and the L.nigrolineata in the Summer. It indicates that, holding all other variables constant (in this case, species), if you change the season variable to Summer you have to add 5.68 to 63.76 to get the mean of L.nigrolineata in the Summer. The value labelled “speciesLittorina saxatilis” is also relative to the intercept. Holding all other variables constant (in this case, season), if you change the species variable to Littorina saxatilis you have to add -7.28 to 63.76 to get the mean of L.saxatilis in the Spring. Similarly, the value labelled “seasonSummer:speciesLittorina saxatilis” is relative to the intercept but the estimate, 10.76 is what you must add additionally. If you change the season variable to Summer and the species variable to Littorina saxatilis you have to add 5.68 (the effect of season), -7.28 (the effect of species) and 10.76 (the additional effect) to to 63.76 to get the mean of L.saxatilis in the Summer. 6.5 Getting predictions from the model You must have all the combination. these are the means for two categorical variables predictions &lt;- data.frame(species = peri_summary$species, season = peri_summary$season) predictions$pred &lt;- predict(mod, newdata = predictions) 6.6 Link to Chapter 2.1 Replacing the terms shown in Figure 2.1 with the values in this example gives us ??. 6.7 Checking assumptions plot(mod, which = 2) plot(mod, which = 1) shapiro.test(mod$res) # # Shapiro-Wilk normality test # # data: mod$res # W = 1, p-value = 0.3 6.8 Post-hoc testing for lm() library(multcomp) generic example. define linfct, mcp multiple comparison procedures can be obtained by fitting the so-called cell-means model based on a new factor derived as the interaction of species and season: periwinkle$seasxspp &lt;- interaction(periwinkle$season, periwinkle$species) mod2 &lt;- lm(data = periwinkle, para ~ seasxspp) mod2_mc &lt;- glht(mod2, linfct = mcp(seasxspp = &quot;Tukey&quot;)) summary(mod2_mc) # # Simultaneous Tests for General Linear Hypotheses # # Multiple Comparisons of Means: Tukey Contrasts # # # Fit: lm(formula = para ~ seasxspp, data = periwinkle) # # Linear Hypotheses: # Estimate # Summer.Littorina nigrolineata - Spring.Littorina nigrolineata == 0 5.68 # Spring.Littorina saxatilis - Spring.Littorina nigrolineata == 0 -7.28 # Summer.Littorina saxatilis - Spring.Littorina nigrolineata == 0 9.16 # Spring.Littorina saxatilis - Summer.Littorina nigrolineata == 0 -12.96 # Summer.Littorina saxatilis - Summer.Littorina nigrolineata == 0 3.48 # Summer.Littorina saxatilis - Spring.Littorina saxatilis == 0 16.44 # Std. Error # Summer.Littorina nigrolineata - Spring.Littorina nigrolineata == 0 3.09 # Spring.Littorina saxatilis - Spring.Littorina nigrolineata == 0 3.09 # Summer.Littorina saxatilis - Spring.Littorina nigrolineata == 0 3.09 # Spring.Littorina saxatilis - Summer.Littorina nigrolineata == 0 3.09 # Summer.Littorina saxatilis - Summer.Littorina nigrolineata == 0 3.09 # Summer.Littorina saxatilis - Spring.Littorina saxatilis == 0 3.09 # t value # Summer.Littorina nigrolineata - Spring.Littorina nigrolineata == 0 1.84 # Spring.Littorina saxatilis - Spring.Littorina nigrolineata == 0 -2.35 # Summer.Littorina saxatilis - Spring.Littorina nigrolineata == 0 2.96 # Spring.Littorina saxatilis - Summer.Littorina nigrolineata == 0 -4.19 # Summer.Littorina saxatilis - Summer.Littorina nigrolineata == 0 1.13 # Summer.Littorina saxatilis - Spring.Littorina saxatilis == 0 5.32 # Pr(&gt;|t|) # Summer.Littorina nigrolineata - Spring.Littorina nigrolineata == 0 0.263 # Spring.Littorina saxatilis - Spring.Littorina nigrolineata == 0 0.093 . # Summer.Littorina saxatilis - Spring.Littorina nigrolineata == 0 0.020 * # Spring.Littorina saxatilis - Summer.Littorina nigrolineata == 0 &lt;0.001 *** # Summer.Littorina saxatilis - Summer.Littorina nigrolineata == 0 0.675 # Summer.Littorina saxatilis - Spring.Littorina saxatilis == 0 &lt;0.001 *** # --- # Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # (Adjusted p values reported -- single-step method) 6.9 Creating a figure #summarise the data ggplot() + geom_point(data = periwinkle, aes(x = season, y = para, colour = species), position = position_jitterdodge(dodge.width = 1, jitter.width = 0.4, jitter.height = 0), size = 2) + geom_errorbar(data = peri_summary, aes(x = season, ymin = mean - se, ymax = mean + se, group = species), width = 0.4, size = 1, position = position_dodge(width = 1)) + geom_errorbar(data = peri_summary, aes(x = season, ymin = mean, ymax = mean, group = species), width = 0.3, size = 1, position = position_dodge(width = 1) ) + scale_x_discrete(name = &quot;Season&quot;) + scale_y_continuous(name = &quot;Number of parasites&quot;, expand = c(0, 0), limits = c(0, 128)) + scale_colour_manual(values = pal4[1:2]) + # Spring:Littorina nigrolineata-Summer:Littorina saxatilis * annotate(&quot;segment&quot;, x = 1.25, xend = 1.75, y = 110, yend = 110, colour = &quot;black&quot;) + annotate(&quot;segment&quot;, x = 1.25, xend = 1.25, y = 110, yend = 105, colour = &quot;black&quot;) + annotate(&quot;segment&quot;, x = 1.75, xend = 1.75, y = 110, yend = 105, colour = &quot;black&quot;) + annotate(&quot;text&quot;, x = 1.5, y = 112, label = &quot;***&quot;, size = 6) + # Summer:Littorina nigrolineata-Spring:Littorina saxatilis: *** annotate(&quot;segment&quot;, x = 1.25, xend = 0.75, y = 90, yend = 90, colour = &quot;black&quot;) + annotate(&quot;segment&quot;, x = 1.25, xend = 1.25, y = 90, yend = 85, colour = &quot;black&quot;) + annotate(&quot;segment&quot;, x = 0.75, xend = 0.75, y = 90, yend = 85, colour = &quot;black&quot;) + annotate(&quot;text&quot;, x = 1, y = 92, label = &quot;**&quot;, size = 6) + # Summer:Littorina saxatilis-Spring:Littorina saxatilis: *** annotate(&quot;segment&quot;, x = 0.75, xend = 1.75, y = 120, yend = 120, colour = &quot;black&quot;) + annotate(&quot;segment&quot;, x = 0.75, xend = 0.75, y = 120, yend = 115, colour = &quot;black&quot;) + annotate(&quot;segment&quot;, x = 1.75, xend = 1.75, y = 120, yend = 115, colour = &quot;black&quot;) + annotate(&quot;text&quot;, x = 1.25, y = 123, label = &quot;***&quot;, size = 6) + theme_classic() + theme(legend.title = element_blank(), legend.position = c(0.85, 0.98)) 6.10 Reporting the results See figure ??. "],
["pois.html", "Chapter 7 GLM for poisson responses 7.1 intro 7.2 build 7.3 output", " Chapter 7 GLM for poisson responses 7.1 intro some stuff introducing pois 7.2 build some stuff about build pois 7.3 output some stuff about pois output "],
["bino.html", "Chapter 8 GLM for binomial responses 8.1 intro 8.2 build 8.3 output", " Chapter 8 GLM for binomial responses 8.1 intro some stuff introducing bino 8.2 build some stuff about build bino 8.3 output some stuff about bino output "],
["summary.html", "Chapter 9 Summary", " Chapter 9 Summary key points where to go next "],
["references.html", "References", " References "]
]
