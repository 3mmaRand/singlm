<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 1 What are GLMs? | singlm: A simple introduction to GLM for analysing Poisson and Binomial responses in R</title>
<meta name="author" content="Emma Rand">
<meta name="description" content="1.1 Overview General Linear models predict the value of a normally distributed response from a linear combination of predictor variables. The Generalised Linear Model is an extension of the...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 1 What are GLMs? | singlm: A simple introduction to GLM for analysing Poisson and Binomial responses in R">
<meta property="og:type" content="book">
<meta property="og:url" content="https://3mmarand.github.io/singlm/what-are-glms-1.html">
<meta property="og:image" content="https://3mmarand.github.io/singlm//images/hex-s.png">
<meta property="og:description" content="1.1 Overview General Linear models predict the value of a normally distributed response from a linear combination of predictor variables. The Generalised Linear Model is an extension of the...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 1 What are GLMs? | singlm: A simple introduction to GLM for analysing Poisson and Binomial responses in R">
<meta name="twitter:site" content="@er13_r">
<meta name="twitter:description" content="1.1 Overview General Linear models predict the value of a normally distributed response from a linear combination of predictor variables. The Generalised Linear Model is an extension of the...">
<meta name="twitter:image" content="https://3mmarand.github.io/singlm//images/hex-s.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.0/transition.js"></script><script src="libs/bs3compat-0.3.0/tabs.js"></script><script src="libs/bs3compat-0.3.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet">
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-115082821-1"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-115082821-1');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="assets/style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">singlm: A simple introduction to GLM for analysing Poisson and Binomial responses in R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome!</a></li>
<li class="book-part">Introduction</li>
<li><a class="active" href="what-are-glms-1.html"><span class="header-section-number">1</span> What are GLMs?</a></li>
<li class="book-part">POISSON GLMs</li>
<li><a class="" href="pois-glm-overview-2.html"><span class="header-section-number">2</span> Poisson GLM overview</a></li>
<li><a class="" href="pois-glm-single-cont.html"><span class="header-section-number">3</span> Single continuous explanatory</a></li>
<li><a class="" href="pois-glm-two-cont.html"><span class="header-section-number">4</span> Two explanatory variables</a></li>
<li class="book-part">BINOMIAL GLMs</li>
<li><a class="" href="bino-glm-overview-5.html"><span class="header-section-number">5</span> Binomial GLM overview</a></li>
<li><a class="" href="bino-glm-single-cont.html"><span class="header-section-number">6</span> Single continuous explanatory</a></li>
<li><a class="" href="summary.html"><span class="header-section-number">7</span> Summary</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/3mmaRand/singlm">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="what-are-glms-1" class="section level1" number="1">
<h1>
<span class="header-section-number">1</span> What are GLMs?<a class="anchor" aria-label="anchor" href="#what-are-glms-1"><i class="fas fa-link"></i></a>
</h1>
<div id="overview-1" class="section level2" number="1.1">
<h2>
<span class="header-section-number">1.1</span> Overview<a class="anchor" aria-label="anchor" href="#overview-1"><i class="fas fa-link"></i></a>
</h2>
<p>General Linear models predict the value of a normally distributed response from a linear combination of predictor variables.</p>
<p>The General<em>ised</em> Linear Model is an extension of the General Linear model for situations where the response variable does not follow the normal distribution. It can, instead, come from a large family of distributions known as the Exponential family which includes the normal, Poisson and binomial distributions. It generalises by allowing the linear model to be related to the response variable by a something we call a <em>link</em> function.</p>
<p>When you have a single explanatory variable, the General Linear model is:</p>
<p><span class="math display" id="eq:lm1">\[\begin{equation}
E(y_{i})=\beta_{0}+\beta_{1}X1_{i}
\tag{1.1}
\end{equation}\]</span></p>
<p>Where:</p>
<ul>
<li>
<span class="math inline">\(y\)</span> is the response variable and <span class="math inline">\(X1\)</span> is the explanatory variable.<br>
</li>
<li>
<span class="math inline">\(i\)</span> is the index so <span class="math inline">\(X1_{i}\)</span> is the <span class="math inline">\(i\)</span>th value of <span class="math inline">\(X1\)</span>
</li>
<li>
<span class="math inline">\(E(y_{i})\)</span> is the expected value of <span class="math inline">\(y\)</span> for the <span class="math inline">\(i\)</span>th value of <span class="math inline">\(X1\)</span>.</li>
<li>
<span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> are the coefficients in the model.</li>
</ul>
<p>And that for the General<em>ised</em> Linear Model is:
<span class="math display" id="eq:glm1">\[\begin{equation}
function(E(y_{i}))=\beta_{0}+\beta_{1}X1_{i}
\tag{1.2}
\end{equation}\]</span></p>
<p>Where:</p>
<ul>
<li>
<span class="math inline">\(function()\)</span> is the link function</li>
</ul>
<p>The link function is a transformation applied to the expected value of the response to link it to the explanatory variables.</p>
<p>If you measured the response for a particular value of <span class="math inline">\(x\)</span> very many times there would be some distribution of those responses. Instead of that distribution having to be normal, it can come from a different distribution such as the Poisson or Binomial distributions. As a consequence, the residuals also come from that distribution. The fact that the residuals can follow a distribution other than normal also means the the variance no longer has to be homogeneous but can change for the values of x.</p>
<p>You can see that the two model equations are similar in structure. This is with good reason - you can think of the general linear model as a special case of generalised linear model when no transformation to the expected value, <span class="math inline">\(E(y_{i})\)</span>, is required.</p>
<p>A very important difference between the general linear model (applied with <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>) and the generalised linear model (applied with <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code>) is that the estimates of the coefficients are given on the scale of the link function. You cannot just read the predicted response at <span class="math inline">\(x=0\)</span> from <span class="math inline">\(\beta_{0}\)</span> - you have to invert the link function to express the coefficients in terms of the response.</p>
<div class="key">
<p>Response variables that are binary or counts can be analysed with GLMs. The estimated coefficients in GLMs have been transformed by a link function. The inverse of the link function has to be applied to them to understand them in terms of the response.</p>
</div>
</div>
<div id="mod-fitting-1" class="section level2" number="1.2">
<h2>
<span class="header-section-number">1.2</span> Model fitting<a class="anchor" aria-label="anchor" href="#mod-fitting-1"><i class="fas fa-link"></i></a>
</h2>
<p>Another important difference between these models is in the measure of fit and the test on that measure of fit. The parameters of General linear models are chosen to minimise the sum of the squared residuals and use <span class="math inline">\(R^2\)</span>, the proportion of variance explained. A variance ratio test, the <em>F</em>-test, is used to determine if the proportion of variance explained is significant.</p>
<p>In GLMS we maximise the log-likelihood of our model (<span class="math inline">\(l\)</span>) to choose our parameter values. This is known as maximum likelihood estimation. The measure of fit used in GLMs is <strong>deviance</strong> where deviance is <span class="math inline">\(-2l\)</span>. Low deviance means a good fit and high deviance a worse fit. Thus maximum likelihood estimation can be thought of as minimising deviance. The test again compares the deviance of predictions from the model with deviance in an intercept only model. This deviance in predictions from the intercept alone is called the Null deviance.</p>
<p>Instead of considering the size of the <span class="math inline">\(R^2\)</span> we consider the reduction in deviance between the null model and the residual deviance (the deviance left over after the model fit). You can consider the residual deviance to play the same role as <span class="math inline">\(SSE\)</span>. The difference between the null model deviance and the residual deviance of the full model has a chi-squared distribution and the test of whether the model is good overall is a “chi-squared test of deviance” This is analogous to the way that general linear model uses the <span class="math inline">\(F\)</span> variance ratio test.</p>
<div class="key">
<p>GLMs maximise log-likelihood to choose coefficient values rather than minimising the sum of the squared residuals (<span class="math inline">\(SSE\)</span>) as in general linear models. Residual deviance rather than <span class="math inline">\(SSE\)</span> represents the unexplained variation in the response and Null deviance is analogous to total sums of squares. Model fit is tested with a chi-squared test of deviance rather than an <span class="math inline">\(F\)</span> test of variance</p>
</div>
<p>The Akaike Information Criterion (AIC) is measure of fit that plays the same role in GLMs that adjusted <span class="math inline">\(R^2\)</span> plays in the general linear model. It is trade-off between the goodness of fit of the model and the simplicity of the model. AIC values can also be determined for general linear models (but adjusted <span class="math inline">\(R^2\)</span> cannot be calculated for GLMs).</p>

<div class="figure" style="text-align: left">
<span style="display:block;" id="fig:Akaike-fig"></span>
<img src="images/Akaike.jpg" alt="Hirotugu Akaike. By The Institute of Statistical Mathematics - The Institute of Statistical Mathematics, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=64389664" width="80%"><p class="caption">
Figure 1.1: Hirotugu Akaike. By The Institute of Statistical Mathematics - The Institute of Statistical Mathematics, CC BY-SA 4.0, <a href="https://commons.wikimedia.org/w/index.php?curid=64389664" class="uri">https://commons.wikimedia.org/w/index.php?curid=64389664</a>
</p>
</div>
</div>
<div id="glm-types-1" class="section level2" number="1.3">
<h2>
<span class="header-section-number">1.3</span> Types of GLM<a class="anchor" aria-label="anchor" href="#glm-types-1"><i class="fas fa-link"></i></a>
</h2>
<p>Poisson GLMs are used when our response is a count. They are also known as GLMs with Poisson errors or Poisson regression. The link function is the natural logarithm, <span class="math inline">\(ln\)</span>, a function you probably know. This means the predictions are log counts and the coefficients have to be exponentiated using <code><a href="https://rdrr.io/r/base/Log.html">exp()</a></code> to get predicted counts because <code><a href="https://rdrr.io/r/base/Log.html">exp()</a></code> is the inverse of <code><a href="https://rdrr.io/r/base/Log.html">log()</a></code>.</p>
<p>In R, the <code><a href="https://rdrr.io/r/base/Log.html">log()</a></code> function computes natural logarithms (<em>i.e.</em>, logs to the base <span class="math inline">\(e\)</span> by default.</p>
<p>Binomial GLMs are used when our response is binary, a zero or one, or a proportion. For example, the response could be died (0) or survived (1), absent (0) or present (1) or right-handed (0) or left-handed (1). Binomial GLMs are also known as GLMs with binomial errors, binomial regression or logistic regression. The link function is <span class="math inline">\(logit\)</span>, a function you may not have heard of before. The predictions are “log-odds.” An “odds” is one probability divided by another. The coefficients have to be exponentiated using <code><a href="https://rdrr.io/r/base/Log.html">exp()</a></code> and interpreted as odds. Often the easiest way to understand the predictions is to use the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> function to get predictions on the scale of the response. If the binomial variable is died (0) or survived(1) these will be probabilities of survival.</p>
<div class="key">
<p>Poisson GLMs are used when our response is a count and the estimates are log counts. Binomial GLMs are used when our response is binary and the estimates a log-odds. The <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> is especially useful in understanding binomial GLMs.</p>
</div>
</div>
<div id="more-than-1-1" class="section level2" number="1.4">
<h2>
<span class="header-section-number">1.4</span> More than one explanatory variable<a class="anchor" aria-label="anchor" href="#more-than-1-1"><i class="fas fa-link"></i></a>
</h2>
<p>When you have more than one explanatory variable these are given as <span class="math inline">\(X2\)</span>, <span class="math inline">\(X3\)</span> and so on up to the <span class="math inline">\(p\)</span>th explanatory variable. Each explanatory variable has its own <span class="math inline">\(\beta\)</span> coefficient.</p>
<p>The general form of the model is:
<span class="math display" id="eq:glm2">\[\begin{equation}
function(E(y_{i}))=\beta_{0}+\beta_{1}X1_{i}+\beta_{2}X2_{i}+...+\beta_{p}Xp_{i}
\tag{1.3}
\end{equation}\]</span></p>
</div>
<div id="glm-in-r-1" class="section level2" number="1.5">
<h2>
<span class="header-section-number">1.5</span> Generalised linear models in R<a class="anchor" aria-label="anchor" href="#glm-in-r-1"><i class="fas fa-link"></i></a>
</h2>
<div id="build-view-1" class="section level3" number="1.5.1">
<h3>
<span class="header-section-number">1.5.1</span> Building and viewing<a class="anchor" aria-label="anchor" href="#build-view-1"><i class="fas fa-link"></i></a>
</h3>
<p>Poisson and binomial generalised linear models (and others) can be carried out with the <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> function in R. It uses the same method, <code><em>response</em> ~ <em>explanatory</em></code> for specifying the model that other functions, including <code>lm(),</code> use. However, you also have to specify the type of GLM using the <code>family</code> argument:</p>
<p>When you have one explanatory variable the command is:</p>
<p><code>glm(data = <em>dataframe</em>, <em>response</em> ~ <em>explanatory</em>, family = <em>distribution</em>(link = <em>linkfunction</em>))</code></p>
<p>For a Poisson GLM this is:</p>
<p><code>glm(data = <em>dataframe</em>, <em>response</em> ~ <em>explanatory</em>, family = poisson(link = log))</code></p>
<p>For a binomial GLM this is:</p>
<p><code>glm(data = <em>dataframe</em>, <em>response</em> ~ <em>explanatory</em>, family = binomial(link = “logit”))</code></p>
<p>The model formula can be developed in the same way we’ve seen previously. When you have two explanatory variable we add the second explanatory variable to the formula using a <code><a href="https://rdrr.io/r/base/Arithmetic.html">+</a></code> or a <code><a href="https://rdrr.io/r/base/Arithmetic.html">*</a></code>. The command is:</p>
<p><code>glm(data = <em>dataframe</em>, <em>response</em> ~ <em>explanatory1</em> + <em>explanatory2</em>, family = <em>distribution</em>(link = <em>linkfunction</em>))</code></p>
<p>or</p>
<p><code>glm(data = <em>dataframe</em>, <em>response</em> ~ <em>explanatory1</em> * <em>explanatory2</em>, family = <em>distribution</em>(link = <em>linkfunction</em>))</code></p>
<p>A model with <code>explanatory1 + explanatory2</code> considers the effects of the two variables independently. A model with <code>explanatory1 * explanatory2</code> considers the effects of the two variables <em>and</em> any interaction between them.</p>
<p>We usually assign the output of <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> commands to an object and view it with <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code>. The typical workflow would be:</p>
<p><code>
mod &lt;- glm(data = <em>dataframe</em>, <em>response</em> ~ <em>explanatory</em>, family = <em>distribution</em>(link = <em>linkfunction</em>))<br>
summary(mod)
</code></p>
<div class="key">
<p><code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> can be used to perform tests using the Generalised Linear Model including Poisson and Binomial regression. The type of GLM needs to be specified.</p>
</div>
<p>Elements of the <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> object include the estimated coefficients can be accessed with <code>mod$coeffients</code>.</p>
</div>
<div id="get-pred-1" class="section level3" number="1.5.2">
<h3>
<span class="header-section-number">1.5.2</span> Getting predictions<a class="anchor" aria-label="anchor" href="#get-pred-1"><i class="fas fa-link"></i></a>
</h3>
<p><code>mod$fitted.values</code> gives the predicted values for the explanatory variable values actually used in the experiment, <em>i.e.</em>, there is a prediction for each row of data. These are given on the scale of the response. This means they will be predicted counts for Poisson GLMs and predicted probabilities for Binomial GLMs.</p>
</div>
<div id="tests-of-the-model" class="section level3" number="1.5.3">
<h3>
<span class="header-section-number">1.5.3</span> Tests of the model<a class="anchor" aria-label="anchor" href="#tests-of-the-model"><i class="fas fa-link"></i></a>
</h3>
<p>With an <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> you get an <em>F</em> variance ratio test of the model over all when you view a summary. It answers the question “does the model explain a significant amount of the variation in the response relative to the response mean?”</p>
<p>With a <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> you do not get a test of the model over all when you view a summary. You have to <em>ask</em> for a chi-squared test of deviance. It answers the question “does the model significantly decrease the deviance relative to the response mean?”
<code>
anova(mod, test = “Chisq”)
</code></p>
<p>To get predictions for a different set of values you need to make a dataframe of the different set of values and use the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> function. When using the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> function we have to specify that we want our predictions on the scale of the response rather than the scale of the link function using the <code>type</code> argument.
The typical workflow would be:</p>
<p><code>predict_for &lt;- data.frame(<em>explanatory</em> = <em>values</em>)<br>
predict_for$pred &lt;- predict(mod, newdata = predict_for, type = “response”)</code></p>

</div>
</div>
</div>



  <div class="chapter-nav">
<div class="prev"><a href="index.html">Welcome!</a></div>
<div class="next"><a href="pois-glm-overview-2.html"><span class="header-section-number">2</span> Poisson GLM overview</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#what-are-glms-1"><span class="header-section-number">1</span> What are GLMs?</a></li>
<li><a class="nav-link" href="#overview-1"><span class="header-section-number">1.1</span> Overview</a></li>
<li><a class="nav-link" href="#mod-fitting-1"><span class="header-section-number">1.2</span> Model fitting</a></li>
<li><a class="nav-link" href="#glm-types-1"><span class="header-section-number">1.3</span> Types of GLM</a></li>
<li><a class="nav-link" href="#more-than-1-1"><span class="header-section-number">1.4</span> More than one explanatory variable</a></li>
<li>
<a class="nav-link" href="#glm-in-r-1"><span class="header-section-number">1.5</span> Generalised linear models in R</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#build-view-1"><span class="header-section-number">1.5.1</span> Building and viewing</a></li>
<li><a class="nav-link" href="#get-pred-1"><span class="header-section-number">1.5.2</span> Getting predictions</a></li>
<li><a class="nav-link" href="#tests-of-the-model"><span class="header-section-number">1.5.3</span> Tests of the model</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/3mmaRand/singlm/blob/master/glm-intro.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/3mmaRand/singlm/edit/master/glm-intro.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>singlm: A simple introduction to GLM for analysing Poisson and Binomial responses in R</strong>" was written by Emma Rand. It was last built on October 2021.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
